spring.application.name=TicketMaster

# HTTP/2 (h2c cleartext)
server.http2.enabled=true

# === Virtual Threads（最關鍵：Tomcat 從 200 線程→無限虛擬線程）===
spring.threads.virtual.enabled=true

# === Tomcat 連接配置（防止 70K QPS 下連接被拒絕）===
server.tomcat.accept-count=8192
server.tomcat.max-connections=65536

# PostgreSQL
spring.datasource.url=jdbc:postgresql://localhost:5432/mydatabase
spring.datasource.username=myuser
spring.datasource.password=secret

# JPA / Hibernate
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.open-in-view=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect

# === HikariCP 連接池（支撐混合流量）===
spring.datasource.hikari.maximum-pool-size=50
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.connection-timeout=5000

# Redis
spring.data.redis.host=localhost
spring.data.redis.port=6379

# === Redis 連接池（為 Step 4 緩存準備）===
spring.data.redis.lettuce.pool.max-active=50
spring.data.redis.lettuce.pool.max-idle=20

# Kafka
spring.kafka.bootstrap-servers=localhost:29092
spring.kafka.streams.application-id=ticketmaster-streams
spring.kafka.streams.properties[default.key.serde]=org.apache.kafka.common.serialization.Serdes$StringSerde
spring.kafka.streams.properties[default.value.serde]=io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde
spring.kafka.streams.properties[schema.registry.url]=http://localhost:8081
spring.kafka.streams.properties[application.server]=${KAFKA_STREAMS_APP_SERVER:localhost:${server.port:8080}}
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
spring.kafka.producer.properties.schema.registry.url=http://localhost:8081

# === Kafka producer 調優（降低批次等待）===
spring.kafka.producer.properties.linger.ms=1
spring.kafka.producer.properties.buffer.memory=67108864
spring.kafka.producer.properties.max.in.flight.requests.per.connection=10

# Kafka Streams tuning
# 本機開發：8 線程，K8s 生產環保持 2（10 pods × 2 = 20 = partitions）
spring.kafka.streams.properties[num.stream.threads]=8
spring.kafka.streams.properties[producer.linger.ms]=1
spring.kafka.streams.properties[producer.batch.size]=2097152
spring.kafka.streams.properties[producer.compression.type]=lz4
spring.kafka.streams.properties[commit.interval.ms]=30
spring.kafka.streams.properties[consumer.fetch.min.bytes]=1024
spring.kafka.streams.properties[consumer.fetch.max.wait.ms]=100
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=io.confluent.kafka.serializers.KafkaAvroDeserializer
spring.kafka.consumer.properties.schema.registry.url=http://localhost:8081
spring.kafka.consumer.properties.specific.avro.reader=true
spring.kafka.consumer.auto-offset-reset=earliest

# Broadcast consumer — each instance gets its own group to receive all messages
app.reservation.notify.group-id=reservation-notify-${random.uuid}

# Section status cache — broadcast to all instances
app.section-status.group-id=section-status-${random.uuid}

# OpenTelemetry (disabled - collector not running in dev environment)
# In K8s, use: otel-collector.observability.svc.cluster.local:4318
# For now, disable to avoid connection errors
management.tracing.sampling.probability=0
