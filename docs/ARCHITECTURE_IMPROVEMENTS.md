# TicketMaster æ¶æ§‹æ”¹é€²å»ºè­° (2026-02-25)

> åŸºæ–¼æ¶æ§‹è©•ä¼°å ±å‘Šçš„å„ªå…ˆç´šæ”¹é€²è·¯ç·šåœ–

## ğŸ“Š ç³»çµ±ç•¶å‰ç‹€æ³

### å„ªå‹¢ â­â­â­â­â­
- **ç„¡é–æ•¸æ“šæµè¨­è¨ˆ**ï¼šé€šé Kafka Streams partition-level ç·šæ€§è™•ç†ï¼Œå„ªé›…åœ°é¿é–‹äº†æ‚²è§€é–å’Œæ¨‚è§€é–çš„é™·é˜±
- **Pre-filter å¿«é€Ÿæ‹’çµ•**ï¼šSectionStatusCache åœ¨åº«å­˜ä¸è¶³æ™‚ç›´æ¥æ‹’çµ•ï¼Œé¿å…è«‹æ±‚é€²å…¥ Kafka
- **DeferredResult ç•°æ­¥æ¨¡å¼**ï¼šé…åˆ Virtual Threadsï¼Œèƒ½æ”¯æ’å¤§é‡ä½µç™¼é€£æ¥
- **ä¸‰è§’è‰²ç¨ç«‹éƒ¨ç½²**ï¼šSpring Profiles + K8s åŸç”Ÿæ”¯æŒç¨ç«‹æ“´å®¹

### ç“¶é ¸ âš ï¸âš ï¸âš ï¸
| ç“¶é ¸ | åš´é‡åº¦ | å½±éŸ¿ | ä¼°ç®— |
|------|--------|------|------|
| **Kafka å–® Broker** | ğŸ”´ Critical | SPOFï¼Œç³»çµ±ç´šæ•…éšœ | ååä¸Šé™ 50-80K msg/sec |
| **SectionSeatState å¤§ Map** | ğŸ”´ Critical | åºåˆ—åŒ–é–‹éŠ·å·¨å¤§ | ~100KB/æ¶ˆæ¯ |
| **Partition/Thread å¤±é…** | ğŸŸ¡ High | è³‡æºæµªè²»ï¼Œrebalance è¤‡é›œ | 40 threads vs 20 partitions |
| **ç¼ºå°‘æ•…éšœæ¢å¾©å„ªåŒ–** | ğŸŸ¡ High | pod é‡å•Ÿå¾Œæ•¸æ“šä¸Ÿå¤± | RocksDB å›æ”¾ 1-10min |
| **é è¨‚çµæœä¸æŒä¹…åŒ–** | ğŸŸ¡ High | ç„¡å¯©è¨ˆæ—¥èªŒï¼ŒæŸ¥è©¢ä¸å¯é  | åªå­˜ Kafka state store |

---

## ğŸš€ Phase 1: åŸºç¤ä¿®å¾© (1-2é€±) - ROI æœ€é«˜

### æ”¹é€² 1.1: ä¿®å¾© seat-processor.yaml èªæ³•éŒ¯èª¤ â±ï¸ 5min
```diff
  spec:
-   replicas: 5
    replicas: 10
```
**ä½ç½®**: `k8s/app/seat-processor.yaml:7-8`
**å½±éŸ¿**: ç„¡ï¼Œä½†ä»£ç¢¼ä¸æ¸…æ™°
**å„ªå…ˆç´š**: Low (ä»£ç¢¼å“è³ª)

---

### æ”¹é€² 1.2: Stream Threads å°é½Š Partitions â±ï¸ 15min
```properties
# application.properties
num.stream.threads=2  # å¾ 4 æ”¹ç‚º 2
```

**ç‚ºä»€éº¼**:
- 10 pods Ã— 4 threads = 40 threads
- ä½†åªæœ‰ 20 partitions
- çµæœï¼š20 å€‹ç·šç¨‹ç©ºé–’ï¼ŒCPU èª¿åº¦é–‹éŠ·å¤§

**æ”¹ç‚º**:
- 10 pods Ã— 2 threads = 20 threads = 20 partitions
- æ¯å€‹ç·šç¨‹å°æ‡‰ä¸€å€‹ partition taskï¼Œå®Œå…¨é£½å’Œ

**æ•ˆæœ**:
- CPU ä½¿ç”¨ç‡ +50% æ›´æœ‰æ•ˆç‡
- Rebalance è¤‡é›œåº¦ -50%
- Zero æˆæœ¬æ”¹é€²

---

### æ”¹é€² 1.3: SectionSeatState ç˜¦èº« (é—œéµ) â±ï¸ 2-3å¤©

**å•é¡Œåˆ†æ**ï¼š

```java
// ç•¶å‰å¯¦ç¾
public class SectionSeatState {
  public Map<String, String> seatStatuses;  // 5000 åº§ä½ = ~100KB!
}

// æ¯æ¬¡åº§ä½åˆ†é…éƒ½è¦åºåˆ—åŒ–æ•´å€‹ map
// section-status topic ç™¼é€æ•´å€‹ map
// æ¯å€‹ API å¯¦ä¾‹éƒ½è¦ååºåˆ—åŒ–æ•´å€‹ map
```

**æ€§èƒ½å½±éŸ¿**ï¼š
- 1000 QPS Ã— 100KB = **100MB/sec** åºåˆ—åŒ–é–‹éŠ·
- Kafka broker ç£ç¢Ÿ I/O çˆ†è¡¨
- ç¶²è·¯é »å¯¬æµªè²»

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```avsc
// ä¿ç•™åŸæœ‰ SectionSeatState for state store (åº§ä½åˆ†é…é‚è¼¯éœ€è¦)
// æ–°å¢ SectionStatusEvent for topic (åªç™¼ count)
{
  "type": "record",
  "name": "SectionStatusEvent",
  "fields": [
    {"name": "eventId", "type": "string"},
    {"name": "section", "type": "string"},
    {"name": "availableCount", "type": "int"}
  ]
}

// ä¿®æ”¹ SectionStatusEmitter
// åªç™¼é€ countï¼Œä¸ç™¼é€ seatStatuses
```

**æ”¹é€²æ­¥é©Ÿ**ï¼š
1. å®šç¾©æ–° Avro schema `SectionStatusEvent`
2. ä¿®æ”¹ `SectionStatusEmitter.processAndForward()` åªç™¼é€ count
3. SectionStatusCache åªéœ€è¦è®€ countï¼ˆç¾åœ¨ä¹Ÿæ˜¯é€™æ¨£ï¼‰
4. é‡å»º section-status topic

**æ•ˆæœ**ï¼š
- æ¶ˆæ¯å¤§å°ï¼š100KB â†’ 50 bytes (2000x ç¸®å°)
- åºåˆ—åŒ–å»¶é² -99%
- **ååæå‡ 3x** (å¾ 10-20K â†’ 30-50K)
- Kafka broker ç£ç¢Ÿå£“åŠ› -99%

**ğŸ¯ æœ€é«˜å„ªå…ˆç´š**ï¼šé€™å€‹æ”¹é€²å–®ç¨å°±èƒ½æå‡ 3 å€åå

---

### æ”¹é€² 1.4: PodDisruptionBudget â±ï¸ 1å¤©

```yaml
# k8s/app/pod-disruption-budgets.yaml
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: api-pdb
  namespace: ticketmaster
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: api
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: seat-processor-pdb
  namespace: ticketmaster
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: seat-processor
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: reservation-processor-pdb
  namespace: ticketmaster
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: reservation-processor
```

**ç‚ºä»€éº¼**ï¼šKafka Streams rebalance æ˜¯å€‹é‡æ“ä½œï¼Œå¦‚æœå¤šå€‹ pod åŒæ™‚ä¸‹ç·šï¼Œæœƒé€ æˆé•·æ™‚é–“çš„æ•¸æ“šä¸å¯ç”¨å’Œå»¶é²åŠ‡å¢ã€‚PDB ç¢ºä¿æ¯æ¬¡åªæœ‰ 1 å€‹ pod ä¸‹ç·šã€‚

**æ•ˆæœ**ï¼š
- Rolling update æ™‚ç„¡ä¸­æ–· â†’ SLA æ›´å¥½
- Rebalance æ™‚é–“å¯æ§

---

## ğŸ“ˆ Phase 2: éŸŒæ€§æå‡ (2-4é€±) - å¿…é ˆåš

### æ”¹é€² 2.1: Kafka å‡ç´šç‚º 3-Broker é›†ç¾¤ â±ï¸ 1é€±

**ç¾ç‹€**ï¼š
- å–® broker (4 CPU, 4GB)
- 1 replica for all topics
- â†’ SPOFï¼Œç£ç¢Ÿæå£ = æ°¸ä¹…æ•¸æ“šä¸Ÿå¤±

**å‡ç´šæ–¹æ¡ˆ**ï¼š

```yaml
# k8s/infra/kafka.yaml (ç°¡åŒ–è¦–åœ–)
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  replicas: 3  # å¾ 1 æ”¹ç‚º 3
  serviceName: kafka
  template:
    spec:
      containers:
      - name: kafka
        env:
        - name: KAFKA_BROKER_RACK
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
          value: "false"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
    spec:
      accessModes: [ReadWriteOnce]
      resources:
        requests:
          storage: 20Gi

---
# é‡å»ºæ‰€æœ‰ topics with replicas=3
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-topics
data:
  create-topics.sh: |
    for topic in reservation-commands reservation-requests reservation-completed section-init section-status; do
      kafka-topics --bootstrap-server kafka-0.kafka:9092 \
        --create --topic $topic \
        --partitions 20 \
        --replication-factor 3 \
        --config min.insync.replicas=2
    done
```

**é…ç½®è®Šæ›´**ï¼š

```properties
# kafka server.properties
log.replication.factor=3
min.insync.replicas=2
default.replication.factor=3
unclean.leader.election.enable=false
log.flush.interval.messages=100000  # å¾ 50000 æ”¹ç‚º 100000

# producer é…ç½® (application.properties)
spring.kafka.producer.acks=all
```

**æ•ˆæœ**ï¼š
- æ¶ˆé™¤ SPOF â†’ ä»»ä¸€ broker å®•æ©Ÿç³»çµ±ç¹¼çºŒé‹è¡Œ
- ååé‡ +2.5x (IO åˆ†æ•£åˆ° 3 å€‹ broker)
- æ•¸æ“šå®‰å…¨ï¼šmin.insync.replicas=2 ä¿è­‰æŒä¹…åŒ–

**ä¼°ç®—æˆæœ¬**ï¼š
- å­˜å„²å¢åŠ  3x (ä½†å¯æ¥å—)
- ç¶²è·¯æµé‡å¢åŠ  2x (replica åŒæ­¥)
- å€¼å¾—ï¼šç”Ÿç”¢ç’°å¢ƒå¿…é ˆåš

**ğŸ¯ å¿…é ˆå„ªå…ˆç´š**

---

### æ”¹é€² 2.2: Seat Processor æ”¹ç‚º StatefulSet + PVC â±ï¸ 1-2å¤©

**ç¾ç‹€**ï¼šDeployment with ephemeral storage
- Pod é‡èª¿åº¦ â†’ RocksDB æ•¸æ“šä¸Ÿå¤±
- éœ€è¦å¾ Kafka changelog topic å®Œæ•´å›æ”¾
- å›æ”¾æ™‚é–“ï¼š**1-10 åˆ†é˜**ï¼ˆå–æ±ºæ–¼æ•¸æ“šé‡ï¼‰
- æœŸé–“ï¼šåº§ä½åˆ†é…å®Œå…¨ä¸å¯ç”¨

**æ”¹ç‚º StatefulSet**ï¼š

```yaml
# k8s/app/seat-processor.yaml (æ›¿æ› Deployment)
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: seat-processor
  namespace: ticketmaster
spec:
  serviceName: seat-processor
  replicas: 10
  selector:
    matchLabels:
      app: seat-processor
  template:
    metadata:
      labels:
        app: seat-processor
    spec:
      containers:
      - name: seat-processor
        image: ticketmaster:latest
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: seat-processor
        - name: SPRING_KAFKA_STREAMS_PROPERTIES_STATE_DIR
          value: /data/kafka-streams
        volumeMounts:
        - name: rocksdb-data
          mountPath: /data
        # ... å…¶ä»–é…ç½®
        resources:
          requests:
            cpu: 2
            memory: 2Gi
          limits:
            cpu: 4
            memory: 4Gi
  volumeClaimTemplates:
  - metadata:
      name: rocksdb-data
    spec:
      accessModes: [ReadWriteOnce]
      storageClassName: fast-ssd  # ä½¿ç”¨å¿«é€Ÿå­˜å„²
      resources:
        requests:
          storage: 5Gi
```

**æ•ˆæœ**ï¼š
- Pod é‡èª¿åº¦ â†’ PVC æ›è¼‰åˆ°åŒä¸€ pod
- RocksDB æ•¸æ“šå®Œæ•´ï¼Œç„¡éœ€å›æ”¾
- æ•…éšœæ¢å¾©æ™‚é–“ï¼š**<1 åˆ†é˜** (vs 1-10min)
- å¯ç”¨æ€§æå‡ 10x

**å­˜å„²è€ƒæ…®**ï¼š
- æ¯å€‹ pod 5GB PVC
- 10 pods = 50GB total (å¯æ¥å—)
- ä½¿ç”¨é«˜é€Ÿå­˜å„² class (SSD/NVMe)

**ğŸ¯ é«˜å„ªå…ˆç´š**ï¼šç”Ÿç”¢ç’°å¢ƒæ•…éšœæ¢å¾© critical

---

### æ”¹é€² 2.3: Reservation çµæœæŒä¹…åŒ–åˆ° PostgreSQL â±ï¸ 1-2å¤©

**ç¾ç‹€**ï¼šé è¨‚æµç¨‹å…¨èµ° Kafkaï¼Œå¾ä¸å¯« PostgreSQL
```java
@Entity
public class Reservation {
  // é€™äº›å­—æ®µå¾æœªè¢«å¡«å……ï¼
  private Status status;        // PENDING/CONFIRMED/CANCELLED
  private Instant completedAt;
}
```

**å½±éŸ¿**ï¼š
- æ²’æœ‰å¯©è¨ˆæ—¥èªŒ â†’ ç„¡æ³•è¿½è¹¤èª°åœ¨ä½•æ™‚é è¨‚äº†ä»€éº¼
- ç„¡æ³•ç”¨ SQL æŸ¥è©¢æ­·å² â†’ å¿…é ˆå¾ Kafka è®€
- æ•…éšœé¢¨éšªï¼šKafka state store æå£ â†’ ç„¡ fallback

**æ”¹é€²æ–¹æ¡ˆ**ï¼š

```java
// æ–°å¢ consumer: reservation-completed â†’ PostgreSQL
@Service
@Profile("api")
public class ReservationPersistenceService {

  @KafkaListener(topics = "reservation-completed")
  public void persistCompletion(ReservationCompletedEvent event) {
    Reservation reservation = reservationRepository.findById(event.getReservationId());
    reservation.setStatus(Status.CONFIRMED);
    reservation.setCompletedAt(Instant.now());
    reservation.setEventId(event.getEventId());
    reservation.setSection(event.getSection());
    reservation.setSeats(event.getSeats());
    reservationRepository.save(reservation);
  }
}
```

**DB é…ç½®**ï¼š
```sql
-- æ–°å¢ç´¢å¼•ä»¥æ”¯æŒå¯©è¨ˆæŸ¥è©¢
CREATE INDEX idx_reservation_user_time ON reservation(user_id, completed_at DESC);
CREATE INDEX idx_reservation_event ON reservation(event_id, completed_at DESC);

-- å­˜å„²éç¨‹ï¼šæ¯æ—¥æ­¸æª”èˆŠæ•¸æ“š
CREATE PROCEDURE archive_old_reservations() AS $$
  INSERT INTO reservation_archive
  SELECT * FROM reservation WHERE completed_at < NOW() - INTERVAL '90 days';
  DELETE FROM reservation WHERE completed_at < NOW() - INTERVAL '90 days';
$$;
```

**æ•ˆæœ**ï¼š
- å®Œæ•´å¯©è¨ˆæ—¥èªŒ
- SQL å¯æŸ¥è©¢
- Kafka state store æå£æ™‚æœ‰å®‰å…¨ç¶²

---

### æ”¹é€² 2.4: ç”¨æˆ¶ç´šå»é‡ â±ï¸ 1å¤©

**å•é¡Œ**ï¼šå®¢æˆ¶ç«¯çŸ­æ™‚é–“å…§é‡è©¦ç›¸åŒé è¨‚è«‹æ±‚
```
ç”¨æˆ¶ click é è¨‚æŒ‰éˆ•
â†’ POST /reservations (timeout å› ç‚ºç¶²è·¯æ…¢)
â†’ ç”¨æˆ¶å†æ¬¡ click (è‡ªå‹•é‡è©¦)
â†’ ç”Ÿæˆ 2 å€‹ä¸åŒ reservationId çš„é è¨‚
```

**è§£æ±ºæ–¹æ¡ˆ**ï¼šRedis dedup

```java
@Service
public class ReservationService {

  public ReservationResponse createReservation(CreateReservationRequest req) {
    // å»é‡ key: userId:eventId:section
    String dedupKey = req.getUserId() + ":" + req.getEventId() + ":" + req.getSection();

    // æª¢æŸ¥ï¼šæœ€è¿‘ 1 å°æ™‚æ˜¯å¦é è¨‚éåŒä¸€ section
    String existingReservationId = redisTemplate.opsForValue().get(dedupKey);
    if (existingReservationId != null) {
      // ç›´æ¥è¿”å›ä¹‹å‰çš„é è¨‚ï¼Œä¸é‡è¤‡æäº¤
      return getExistingReservation(existingReservationId);
    }

    // çœŸæ­£æäº¤é è¨‚
    ReservationCompletedEvent result = submitReservation(req);
    String reservationId = result.getReservationId();

    // è¨˜éŒ„ï¼š1 å°æ™‚å…§ä¸é‡è¤‡æäº¤
    redisTemplate.opsForValue().set(
      dedupKey,
      reservationId,
      Duration.ofHours(1)
    );

    return new ReservationResponse(reservationId, result);
  }
}
```

**æ•ˆæœ**ï¼š
- é˜²æ­¢é‡è¤‡é è¨‚
- é‡è©¦å®‰å…¨
- æ”¹å–„ UXï¼šå¿«é€Ÿè¿”å›çµæœ vs Kafka æ’éšŠ

---

## ğŸ¯ Phase 3: æ€§èƒ½èˆ‡å¯è§€æ¸¬æ€§ (4-8é€±)

### æ”¹é€² 3.1: HPA (Horizontal Pod Autoscaler) â±ï¸ 1day

```yaml
# k8s/app/api-hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-hpa
  namespace: ticketmaster
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 30
      policies:
      - type: Percent
        value: 100
        periodSeconds: 30
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Pods
        value: 1
        periodSeconds: 60
```

**ç‚ºä»€éº¼åª HPA API**ï¼š
- Kafka Streams rebalance æˆæœ¬é«˜ â†’ å›ºå®š seat/reservation å‰¯æœ¬æ•¸
- API å±¤ç„¡ç‹€æ…‹ â†’ å¿«é€Ÿæ“´ç¸®å®¹ç„¡å½±éŸ¿

**æ•ˆæœ**ï¼š
- ä½å³°æ™‚ 3 pods â†’ ç¯€çœæˆæœ¬ 70%
- é«˜å³°æ™‚è‡ªå‹•æ“´åˆ° 20 pods
- SLA æ›´å¥½

---

### æ”¹é€² 3.2: Redis Cache for Tickets â±ï¸ 1-2å¤©

```java
@Service
public class TicketService {

  public List<Ticket> getAvailableTicketsByEvent(String eventId) {
    // 1. Check Redis cache
    String cacheKey = "tickets:event:" + eventId;
    List<Ticket> cached = redisTemplate.opsForValue().get(cacheKey);
    if (cached != null) {
      return cached;
    }

    // 2. Query from DB if cache miss
    List<Ticket> tickets = ticketRepository.findAvailableByEvent(eventId);

    // 3. Cache with 10 second TTL
    redisTemplate.opsForValue().set(
      cacheKey,
      tickets,
      Duration.ofSeconds(10)
    );

    return tickets;
  }
}

// ç•¶ section-status æ›´æ–°æ™‚ï¼Œä½¿ ticket cache å¤±æ•ˆ
@KafkaListener(topics = "section-status")
public void invalidateTicketCache(SectionStatusEvent event) {
  String cacheKey = "tickets:event:" + event.getEventId();
  redisTemplate.delete(cacheKey);
}
```

**æ•ˆæœ**ï¼š
- P99 å»¶é² -50%
- PostgreSQL æŸ¥è©¢æ¸›å°‘ 90%
- æ¶ç¥¨é«˜å³°æœŸæŸ¥è©¢å¿«é€Ÿè¿”å›

---

### æ”¹é€² 3.3: OTel æ­£å¼å•Ÿç”¨ + ç›£æ§ â±ï¸ 1day

```yaml
# k8s/app/configmap.yaml
data:
  # å•Ÿç”¨ tracing
  MANAGEMENT_TRACING_ENABLED: "true"
  MANAGEMENT_OTLP_METRICS_EXPORT_ENABLED: "true"
  MANAGEMENT_OTLP_TRACING_ENDPOINT: "http://otel-collector.observability:4318"

  # Sampling: é¿å… trace æ•¸æ“šçˆ†ç‚¸
  OTEL_TRACES_SAMPLER: "traceidratio"
  OTEL_TRACES_SAMPLER_ARG: "0.1"  # 10% sampling
```

**Grafana Dashboard**ï¼š

```
è¡Œ 1 (åå):
  - kafka.producer.record-send-total (QPS)
  - kafka.consumer.records-consumed-total

è¡Œ 2 (å»¶é²):
  - kafka.streams.stream-thread.process-latency-avg
  - http.server.request.duration (P50/P95/P99)

è¡Œ 3 (å¥åº·):
  - kafka.consumer.records-lag-max âš ï¸ æœ€é—œéµ
  - kafka.topic.size (ç£ç¢Ÿä½¿ç”¨)
  - rocksdb.write-latency-avg

è¡Œ 4 (æ‡‰ç”¨):
  - pending_requests (DeferredResult)
  - pre_filter_rejection_rate
  - reservation_timeout_rate
```

**é—œéµå‘Šè­¦**ï¼š

```yaml
# Prometheus alert rules
groups:
- name: ticketmaster
  rules:
  - alert: HighConsumerLag
    expr: kafka_consumer_records_lag_max > 10000
    for: 1m
    severity: critical

  - alert: HighTimeoutRate
    expr: rate(reservation_timeout_total[1m]) > 0.05
    for: 30s
    severity: critical

  - alert: SeatProcessorSlowdown
    expr: kafka_streams_stream_thread_process_latency_avg > 50
    for: 1m
    severity: warning

  - alert: KafkaDiskFull
    expr: kafka_topic_size_bytes > 100 * 1024 * 1024 * 1024
    for: 5m
    severity: warning
```

**æ•ˆæœ**ï¼š
- å®Œæ•´å¯è§€æ¸¬æ€§ âœ“
- æ•…éšœç§’ç´šç™¼ç¾
- æ ¹å› åˆ†ææœ‰æ•¸æ“šæ”¯æ’

---

### æ”¹é€² 3.4: SectionStatusCache é ç†± â±ï¸ 1day

**å•é¡Œ**ï¼šç³»çµ±å•Ÿå‹•æ™‚ cache ç‚ºç©ºï¼Œæ—©æœŸè«‹æ±‚éƒ½é€²å…¥ Kafka

**è§£æ±ºæ–¹æ¡ˆ**ï¼š

```java
@Component
public class SectionStatusCacheWarmer {

  @Autowired
  private SectionStatusCache cache;

  @Autowired
  private KafkaTemplate<String, SectionStatusEvent> kafkaTemplate;

  @Bean
  public ApplicationRunner warmupCache() {
    return args -> {
      // 1. å‰µå»º consumerï¼Œå¾ earliest è®€å–
      Map<String, Object> consumerProps = new HashMap<>();
      consumerProps.put("bootstrap.servers", kafkaProperties.getBootstrapServers());
      consumerProps.put("group.id", "cache-warmer");
      consumerProps.put("auto.offset.reset", "earliest");

      KafkaConsumer<String, SectionStatusEvent> consumer = new KafkaConsumer<>(consumerProps);
      consumer.subscribe(Arrays.asList("section-status"));

      // 2. æ¶ˆè²»æ‰€æœ‰æ¶ˆæ¯åˆ° cache
      int emptyPollCount = 0;
      while (emptyPollCount < 10) {  // 10 æ¬¡ç©º poll å‰‡èªç‚ºå®Œæˆ
        ConsumerRecords<String, SectionStatusEvent> records = consumer.poll(Duration.ofSeconds(1));
        if (records.isEmpty()) {
          emptyPollCount++;
        } else {
          emptyPollCount = 0;
          for (ConsumerRecord<String, SectionStatusEvent> record : records) {
            cache.put(record.value());
          }
        }
      }

      consumer.close();
      logger.info("Cache warmed up with {} entries", cache.size());
    };
  }

  // Readiness probe: åªåœ¨ cache é ç†±å®Œå¾Œæ‰è¿”å› ready
  @GetMapping("/health/ready")
  public ResponseEntity<?> readiness() {
    if (cache.isEmpty()) {
      return ResponseEntity.status(503).build();
    }
    return ResponseEntity.ok("Ready");
  }
}
```

**é…ç½®**ï¼š

```yaml
# k8s/app/api.yaml
readinessProbe:
  httpGet:
    path: /health/ready  # è€Œé /actuator/health
    port: 8080
  initialDelaySeconds: 30  # çµ¦äºˆè¶³å¤ æ™‚é–“é ç†±
  periodSeconds: 5
```

**æ•ˆæœ**ï¼š
- å•Ÿå‹•æ™‚ cache 100% å¡«æ»¿
- ç„¡å•Ÿå‹•é¢¨æš´
- readiness probe ç¢ºä¿æœå‹™çœŸæ­£æº–å‚™å¥½

---

## ğŸ“‹ æœ€çµ‚æ”¹é€²æª¢æŸ¥æ¸…å–®

### Phase 1 (ç«‹å³åŸ·è¡Œ)
- [ ] ä¿®å¾© seat-processor.yaml é‡è¤‡ replicas
- [ ] ä¿®æ”¹ num.stream.threads=2
- [ ] SectionSeatState ç˜¦èº« (å®šç¾©æ–° schema + ä¿®æ”¹ emitter)
- [ ] æ·»åŠ æ‰€æœ‰ deployment çš„ PDB

**é æœŸè€—æ™‚**: 1-2 é€±
**é æœŸæ”¶ç›Š**: åå 3x + è³‡æºæ•ˆç‡ +50%

### Phase 2 (1 å€‹æœˆå…§)
- [ ] Kafka å‡ç´š 3-broker + topic replication=3
- [ ] seat-processor æ”¹ç‚º StatefulSet
- [ ] ReservationPersistenceService å¯¦ç¾
- [ ] Redis dedup é‚è¼¯

**é æœŸè€—æ™‚**: 2-4 é€±
**é æœŸæ”¶ç›Š**: åå 2.5x + æ•…éšœæ¢å¾© 10x + å¯©è¨ˆå®Œæ•´

### Phase 3 (2 å€‹æœˆå…§)
- [ ] HPA é…ç½®
- [ ] Ticket Redis cache
- [ ] OTel å•Ÿç”¨ + Grafana dashboard
- [ ] Cache warmer
- [ ] å£“æ¸¬é©—è­‰

**é æœŸè€—æ™‚**: 4-8 é€±
**é æœŸæ”¶ç›Š**: SLA æå‡ + æˆæœ¬å„ªåŒ– + å®Œæ•´å¯è§€æ¸¬æ€§

---

## ğŸ“Š æ•ˆæœé‡åŒ–

| æŒ‡æ¨™ | ç¾ç‹€ | Phase 1 | Phase 1+2 | Phase 1+2+3 |
|------|------|---------|-----------|------------|
| **ååé‡** (QPS) | 10-20K | 30-50K | 50-100K | 100K+ |
| **P99 å»¶é²** | 100-200ms | 50-100ms | 20-50ms | 10-20ms |
| **æ•…éšœæ¢å¾©** | 1-10min | 1-10min | <1min | <1min |
| **API å‰¯æœ¬** | 10 å›ºå®š | 10 å›ºå®š | 10 å›ºå®š | 3-20 auto |
| **Kafka SPOF** | æ˜¯ | æ˜¯ | å¦ | å¦ |
| **å¯©è¨ˆæ—¥èªŒ** | å¦ | å¦ | æ˜¯ | æ˜¯ |
| **å¯è§€æ¸¬æ€§** | åŸºç¤ | åŸºç¤ | åŸºç¤ | å®Œæ•´ |

---

## ğŸ¯ æ ¸å¿ƒå»ºè­°å„ªå…ˆé †åº

1. **ç«‹å³ (é€±å…§)**: ä¿®å¾©èªæ³• + num.stream.threads + SectionSeatState ç˜¦èº« â†’ **3x ååç«‹ç«¿è¦‹å½±**
2. **1 å€‹æœˆå…§**: Kafka HA + StatefulSet â†’ **ç”Ÿç”¢å¯é æ€§åŸºç¤**
3. **2 å€‹æœˆå…§**: HPA + OTel â†’ **é‹ç¶­æˆç†Ÿåº¦**

ç¥ä½ æ”¹é€²é †åˆ©ï¼ğŸš€
